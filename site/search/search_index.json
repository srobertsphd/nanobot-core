{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"NanoBot Documentation","text":"<p>Welcome to the NanoBot documentation. This site provides comprehensive information about using and extending the NanoBot system.</p>"},{"location":"#what-is-nanobot","title":"What is NanoBot?","text":"<p>NanoBot is a document processing and retrieval system with vector search capabilities. It allows you to:</p> <ul> <li>Process documents (PDF, DOCX, TXT)</li> <li>Chunk documents into manageable pieces</li> <li>Generate vector embeddings using OpenAI</li> <li>Store and search documents using semantic similarity</li> </ul>"},{"location":"#quick-navigation","title":"Quick Navigation","text":"<ul> <li>Getting Started - Installation and basic setup</li> <li>User Guide - Detailed usage instructions</li> <li>API Reference - Technical reference for developers</li> <li>Examples - Code examples and tutorials</li> </ul>"},{"location":"getting-started/","title":"Getting Started with NanoBot","text":"<p>This guide will help you set up and start using NanoBot.</p>"},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10+</li> <li>PostgreSQL with pgvector extension</li> <li>OpenAI API key</li> </ul>"},{"location":"getting-started/#setup","title":"Setup","text":"<ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/yourusername/nanobot-poc.git\ncd nanobot-poc\n</code></pre></p> </li> <li> <p>Create a virtual environment:    <pre><code>python -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>Install dependencies:    <pre><code>pip install -r requirements.txt\n</code></pre></p> </li> <li> <p>Set up environment variables:    Create a <code>.env</code> file with the following variables:    <pre><code>OPENAI_API_KEY=your_openai_api_key\nLOCAL_DB_NAME=nanobot\nLOCAL_DB_USER=postgres\nLOCAL_DB_PASSWORD=your_password\nLOCAL_DB_HOST=localhost\nLOCAL_DB_PORT=5432\nLOGFIRE_TOKEN=your_logfire_token\n</code></pre></p> </li> <li> <p>Initialize the database:    <pre><code>python -m app.database.db_setup\n</code></pre></p> </li> </ol>"},{"location":"getting-started/#running-the-application","title":"Running the Application","text":"<p>Start the Streamlit web interface:</p> <pre><code>streamlit run nanobot_poc.py\n</code></pre> <p>This will open a web browser with the NanoBot interface.</p>"},{"location":"user-guide/document-processing/","title":"Document Processing","text":"<p>This guide explains how NanoBot processes documents, from initial conversion to chunking and embedding.</p>"},{"location":"user-guide/document-processing/#supported-document-types","title":"Supported Document Types","text":"<p>NanoBot supports various document types through its document conversion pipeline:</p> <ul> <li>PDF (.pdf): Full support for text extraction, including tables and basic formatting</li> <li>Microsoft Word (.docx): Support for text, tables, and document structure</li> <li>Text files (.txt): Plain text processing</li> <li>Web Pages (URLs): Extract content directly from web pages</li> </ul>"},{"location":"user-guide/document-processing/#document-processing-pipeline","title":"Document Processing Pipeline","text":"<p>The document processing pipeline consists of three main stages:</p> <ol> <li>Document Conversion: Converting documents to a structured format</li> <li>Chunking: Breaking documents into manageable pieces</li> <li>Embedding: Generating vector representations for each chunk</li> </ol>"},{"location":"user-guide/document-processing/#document-conversion","title":"Document Conversion","text":"<p>The first step in processing a document is converting it to a structured format that preserves the document's content and structure. This is handled by the <code>DocumentService</code> class using the Docling library.</p> <pre><code>from app.services.document_service import DocumentService\n\n# Initialize the service\ndocument_service = DocumentService()\n\n# Convert a document\nconverted_doc = document_service.convert_document(\"path/to/document.pdf\")\n</code></pre> <p>During conversion, NanoBot: - Extracts text content - Preserves document structure (headings, paragraphs) - Identifies metadata (title, author, etc.) - Optionally saves intermediate formats for debugging</p>"},{"location":"user-guide/document-processing/#chunking-strategies","title":"Chunking Strategies","text":"<p>After conversion, documents are split into chunks using one of several chunking strategies. Each strategy is optimized for different use cases:</p> Strategy Description Best For default Standard chunking with moderate chunk size General purpose use balanced Balanced approach between context preservation and chunk size Most document types fine_grained Smaller chunks for more precise retrieval Technical documents, reference materials context Larger chunks that preserve more context Q&amp;A, summarization tasks hierarchical Chunks based on document's natural hierarchy Structured documents with clear sections <p>The chunking process is handled by the <code>ChunkingService</code> class:</p> <pre><code>from app.services.chunking_service import ChunkingService\n\n# Initialize the service\nchunking_service = ChunkingService()\n\n# Get information about available strategies\nstrategies = chunking_service.get_available_strategies()\n\n# Chunk a document using a specific strategy\nchunks = chunking_service.chunk_document(document, strategy=\"balanced\")\n\n# Process chunks to extract metadata\nprocessed_chunks = chunking_service.process_chunks(chunks, chunking_strategy=\"balanced\")\n</code></pre>"},{"location":"user-guide/document-processing/#embedding-generation","title":"Embedding Generation","text":"<p>The final step is generating vector embeddings for each chunk using OpenAI's embedding models. These embeddings capture the semantic meaning of the text, enabling similarity search.</p> <pre><code># Generate embeddings for chunks\nchunks_with_embeddings = document_service.get_embeddings_for_chunks(processed_chunks)\n</code></pre> <p>NanoBot uses OpenAI's text embedding models to generate high-dimensional vector representations of each chunk.</p>"},{"location":"user-guide/document-processing/#complete-processing-example","title":"Complete Processing Example","text":"<p>Here's a complete example of processing a document from start to finish:</p> <pre><code>from app.database.transaction import transaction\nfrom app.services.document_service import DocumentService\n\n# Initialize the service\ndocument_service = DocumentService()\n\n# Process a document with the complete pipeline\nwith transaction() as conn:\n    chunks_with_embeddings = document_service.process_document(\n        doc_path=\"path/to/document.pdf\",\n        chunking_strategy=\"balanced\",\n        save_intermediate=True\n    )\n\n    # Now you can insert these chunks into the database\n    # (See the database documentation for details)\n</code></pre>"},{"location":"user-guide/document-processing/#using-the-streamlit-interface","title":"Using the Streamlit Interface","text":"<p>For a more user-friendly experience, you can use the Streamlit interface to process documents:</p> <ol> <li> <p>Start the Streamlit app:    <pre><code>streamlit run nanobot_poc.py\n</code></pre></p> </li> <li> <p>Navigate to the \"Upload\" section</p> </li> <li>Upload your document</li> <li>Select a chunking strategy from the dropdown</li> <li>Click \"Process Document\"</li> </ol> <p>The interface will show progress as the document is processed and provide feedback on the number of chunks created.</p>"},{"location":"user-guide/document-processing/#best-practices","title":"Best Practices","text":"<ul> <li>Choose the right chunking strategy for your document type and use case</li> <li>Process similar documents with the same strategy for consistent results</li> <li>Use meaningful filenames to help with filtering during retrieval</li> <li>Consider document structure when choosing a chunking strategy</li> <li>Monitor token usage when processing large documents</li> </ul>"},{"location":"user-guide/vector-search/","title":"Vector Search","text":"<p>This guide explains how to use NanoBot's vector search capabilities to find relevant information in your processed documents.</p>"},{"location":"user-guide/vector-search/#understanding-vector-search","title":"Understanding Vector Search","text":"<p>NanoBot uses vector similarity search to find information in your documents. Unlike traditional keyword search, vector search understands the semantic meaning of your query, allowing it to find relevant information even when the exact words don't match.</p>"},{"location":"user-guide/vector-search/#how-it-works","title":"How It Works","text":"<ol> <li>Your query is converted to a vector embedding using the same model used for document chunks</li> <li>The database finds chunks with vectors most similar to your query vector</li> <li>Results are ranked by similarity score (higher is better)</li> <li>Optional filters can narrow down results by document or chunking strategy</li> </ol>"},{"location":"user-guide/vector-search/#basic-search","title":"Basic Search","text":"<p>The simplest way to search is to provide a query text:</p> <pre><code>from app.database.transaction import transaction\nfrom app.database.db_retrieval import search_similar_chunks\n\nwith transaction() as conn:\n    results = search_similar_chunks(\n        conn=conn,\n        query_text=\"What is machine learning?\",\n        limit=5  # Return top 5 results\n    )\n\n    # Display results\n    for result in results:\n        print(f\"Similarity: {result['similarity']:.4f}\")\n        print(f\"Text: {result['text'][:200]}...\")\n        print(\"---\")\n</code></pre>"},{"location":"user-guide/vector-search/#filtered-search","title":"Filtered Search","text":"<p>You can narrow down search results using filters:</p> <pre><code>from app.database.transaction import transaction\nfrom app.database.db_retrieval import search_similar_chunks_with_filters\n\nwith transaction() as conn:\n    results = search_similar_chunks_with_filters(\n        conn=conn,\n        query_text=\"What is machine learning?\",\n        limit=5,\n        chunking_strategy=\"balanced\",  # Filter by chunking strategy\n        filename=\"machine_learning.pdf\"  # Filter by filename\n    )\n</code></pre>"},{"location":"user-guide/vector-search/#available-filters","title":"Available Filters","text":"<ul> <li>chunking_strategy: Filter by the chunking strategy used when processing the document</li> <li>filename: Filter by the source document filename</li> </ul>"},{"location":"user-guide/vector-search/#getting-metadata","title":"Getting Metadata","text":"<p>To help with filtering, you can retrieve available metadata values:</p> <pre><code>from app.database.transaction import transaction\nfrom app.database.db_retrieval import get_chunking_strategies, get_filenames\n\nwith transaction() as conn:\n    # Get available chunking strategies\n    strategies = get_chunking_strategies(conn)\n    print(f\"Available strategies: {strategies}\")\n\n    # Get available filenames\n    filenames = get_filenames(conn)\n    print(f\"Available files: {filenames}\")\n</code></pre>"},{"location":"user-guide/vector-search/#understanding-search-results","title":"Understanding Search Results","text":"<p>Each search result contains:</p> <ul> <li>text: The content of the chunk</li> <li>similarity: A score between 0 and 1 indicating how similar the chunk is to your query (higher is better)</li> <li>metadata: Additional information about the chunk, including:</li> <li>filename: The source document</li> <li>page_numbers: The pages where this chunk appears</li> <li>title: The document title or section heading</li> <li>headings: List of headings associated with this chunk</li> <li>chunking_strategy: The strategy used to create this chunk</li> </ul>"},{"location":"user-guide/vector-search/#using-the-streamlit-interface","title":"Using the Streamlit Interface","text":"<p>The Streamlit interface provides a user-friendly way to search your documents:</p> <ol> <li> <p>Start the Streamlit app:    <pre><code>streamlit run nanobot_poc.py\n</code></pre></p> </li> <li> <p>Enter your query in the search box</p> </li> <li>Use the sidebar to configure search parameters:</li> <li>Number of chunks to retrieve</li> <li>Chunking strategy filter</li> <li>Source document filter</li> <li>Click \"Search\" to execute the query</li> <li>View the results, which include:</li> <li>Chunk text</li> <li>Similarity score</li> <li>Source document and page numbers</li> <li>Other metadata</li> </ol>"},{"location":"user-guide/vector-search/#advanced-usage","title":"Advanced Usage","text":""},{"location":"user-guide/vector-search/#combining-with-openai","title":"Combining with OpenAI","text":"<p>You can use the retrieved chunks as context for OpenAI to generate more comprehensive answers:</p> <pre><code>from app.services.openai_service import get_chat_response\nfrom app.database.transaction import transaction\nfrom app.database.db_retrieval import search_similar_chunks_with_filters\n\nwith transaction() as conn:\n    # Search for relevant chunks\n    chunks = search_similar_chunks_with_filters(\n        conn=conn,\n        query_text=\"What is machine learning?\",\n        limit=5\n    )\n\n    # Use chunks as context for OpenAI\n    response = get_chat_response(\n        prompt=\"What is machine learning?\",\n        context_chunks=chunks\n    )\n\n    print(response)\n</code></pre>"},{"location":"user-guide/vector-search/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Limit: Adjust the <code>limit</code> parameter based on your needs. Higher values return more results but may include less relevant chunks.</li> <li>Filters: Use filters to narrow down results when you know which documents or chunking strategies are most relevant.</li> <li>Query Formulation: Be specific in your queries for better results. Vector search works best with clear, focused questions.</li> </ul>"},{"location":"user-guide/vector-search/#best-practices","title":"Best Practices","text":"<ul> <li>Start broad, then narrow: Begin with unfiltered searches, then add filters if needed</li> <li>Experiment with chunking strategies: Different strategies work better for different types of queries</li> <li>Use natural language: Phrase queries as you would ask a human</li> <li>Provide context: Longer, more detailed queries often yield better results</li> <li>Review metadata: Check the source document and page numbers to understand where information comes from</li> </ul>"}]}