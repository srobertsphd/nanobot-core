{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output of the docling document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements and first conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sng/nanobot-poc/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from docling.chunking import HierarchicalChunker, HybridChunker\n",
    "from docling.document_converter import DocumentConverter\n",
    "from app.utils.tokenizer import OpenAITokenizerWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = DocumentConverter()\n",
    "doc_path = \"/home/sng/nanobot-poc/data/test/grant_decision_email_single_page.pdf\"\n",
    "result = converter.convert(doc_path)\n",
    "document = result.document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = OpenAITokenizerWrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Document Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document attributes (data):\n",
      "- body: self_ref='#/body' parent=None children=[RefItem(cref='#/texts/0'), RefItem(cref='#/texts/1'), RefItem(cref='#/texts/2'), RefItem(cref='#/groups/0'), RefItem(cref='#/texts/5'), RefItem(cref='#/texts/6'), RefItem(cref='#/texts/7'), RefItem(cref='#/texts/8'), RefItem(cref='#/texts/9'), RefItem(cref='#/texts/10'), RefItem(cref='#/texts/11'), RefItem(cref='#/texts/12'), RefItem(cref='#/texts/13'), RefItem(cref='#/texts/14')] content_layer=<ContentLayer.BODY: 'body'> name='_root_' label=<GroupLabel.UNSPECIFIED: 'unspecified'>\n",
      "- furniture: self_ref='#/furniture' parent=None children=[] content_layer=<ContentLayer.FURNITURE: 'furniture'> name='_root_' label=<GroupLabel.UNSPECIFIED: 'unspecified'>\n",
      "- groups: [GroupItem(self_ref='#/groups/0', parent=RefItem(cref='#/body'), children=[RefItem(cref='#/texts/3'), RefItem(cref='#/texts/4')], content_layer=<ContentLayer.BODY: 'body'>, name='group', label=<GroupLabel.KEY_VALUE_AREA: 'key_value_area'>)]\n",
      "- key_value_items: []\n",
      "- model_computed_fields: {}\n",
      "- model_config: {}\n",
      "- model_extra: None\n",
      "- model_fields: {'schema_name': FieldInfo(annotation=Literal['DoclingDocument'], required=False, default='DoclingDocument'), 'version': FieldInfo(annotation=str, required=False, default='1.1.0', metadata=[StringConstraints(strip_whitespace=None, to_upper=None, to_lower=None, strict=True, min_length=None, max_length=None, pattern='^(?P<major>0|[1-9]\\\\d*)\\\\.(?P<minor>0|[1-9]\\\\d*)\\\\.(?P<patch>0|[1-9]\\\\d*)(?:-(?P<prerelease>(?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\\\.(?:0|[1-9]\\\\d*|\\\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))?(?:\\\\+(?P<buildmetadata>[0-9a-zA-Z-]+(?:\\\\.[0-9a-zA-Z-]+)*))?$')]), 'name': FieldInfo(annotation=str, required=True), 'origin': FieldInfo(annotation=Union[DocumentOrigin, NoneType], required=False, default=None), 'furniture': FieldInfo(annotation=GroupItem, required=False, default=GroupItem(self_ref='#/furniture', parent=None, children=[], content_layer=<ContentLayer.FURNITURE: 'furniture'>, name='_root_', label=<GroupLabel.UNSPECIFIED: 'unspecified'>), deprecated=True), 'body': FieldInfo(annotation=GroupItem, required=False, default=GroupItem(self_ref='#/body', parent=None, children=[], content_layer=<ContentLayer.BODY: 'body'>, name='_root_', label=<GroupLabel.UNSPECIFIED: 'unspecified'>)), 'groups': FieldInfo(annotation=List[GroupItem], required=False, default=[]), 'texts': FieldInfo(annotation=List[Union[SectionHeaderItem, ListItem, TextItem, CodeItem]], required=False, default=[]), 'pictures': FieldInfo(annotation=List[PictureItem], required=False, default=[]), 'tables': FieldInfo(annotation=List[TableItem], required=False, default=[]), 'key_value_items': FieldInfo(annotation=List[KeyValueItem], required=False, default=[]), 'pages': FieldInfo(annotation=Dict[int, PageItem], required=False, default={})}\n",
      "- model_fields_set: {'name', 'origin'}\n",
      "- name: grant_decision_email_single_page\n",
      "- origin: mimetype='application/pdf' binary_hash=1563881226811200184 filename='grant_decision_email_single_page.pdf' uri=None\n",
      "- pages: {1: PageItem(size=Size(width=612.0, height=792.0), image=None, page_no=1)}\n",
      "- pictures: []\n",
      "- schema_name: DoclingDocument\n",
      "- tables: []\n",
      "- texts: [SectionHeaderItem(self_ref='#/texts/0', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=743.927001953125, r=436.2510070800781, b=737.0759887695312, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 61))], orig='FuzeHub Manufacturing Grant 2024 Round 2 Application Decision', text='FuzeHub Manufacturing Grant 2024 Round 2 Application Decision', level=1), SectionHeaderItem(self_ref='#/texts/1', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.SECTION_HEADER: 'section_header'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=718.6519775390625, r=254.47900390625, b=712.2039794921875, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 31))], orig='FuzeHub Fund <fund@fuzehub.com>', text='FuzeHub Fund <fund@fuzehub.com>', level=1), TextItem(self_ref='#/texts/2', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=701.552001953125, r=155.86099243164062, b=696.7160034179688, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 22))], orig='Wed 2024-07-24 9:26 AM', text='Wed 2024-07-24 9:26 AM'), TextItem(self_ref='#/texts/3', parent=RefItem(cref='#/groups/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=685.802, r=242.641, b=680.966, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 44))], orig='To:  Samantha Roberts <sroberts@gc.cuny.edu>', text='To:  Samantha Roberts <sroberts@gc.cuny.edu>'), TextItem(self_ref='#/texts/4', parent=RefItem(cref='#/groups/0'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=673.802, r=424.985, b=668.966, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 81))], orig='Cc:  Yuki Chen <xchen4@gc.cuny.edu>;  markk@kepcopower.com <markk@kepcopower.com>', text='Cc:  Yuki Chen <xchen4@gc.cuny.edu>;  markk@kepcopower.com <markk@kepcopower.com>'), TextItem(self_ref='#/texts/5', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=92.37899780273438, t=628.2769775390625, r=524.8590087890625, b=612.593994140625, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 128))], orig='* This email originates from a sender outside of CUNY. Verify the sender before replying or clicking on links and attachments. *', text='* This email originates from a sender outside of CUNY. Verify the sender before replying or clicking on links and attachments. *'), TextItem(self_ref='#/texts/6', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=571.697021484375, r=111.93299865722656, b=566.708984375, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 13))], orig='July 24, 2024', text='July 24, 2024'), TextItem(self_ref='#/texts/7', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=531.197021484375, r=177.17799377441406, b=526.208984375, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 26))], orig='Dear Dr. Samantha Roberts,', text='Dear Dr. Samantha Roberts,'), TextItem(self_ref='#/texts/8', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=504.1969909667969, r=563.2479858398438, b=458.7090148925781, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 346))], orig='Thank you for  subming a grant applicaon for the Jeff Lawrence Innovaon Fund. For Round 2 of the 2024 Manufacturing  Grants,  we  received  58  eligible  applicaons  that  were  carefully  reviewed  by  our  panel  of individuals with experse within the manufacturing, entrepreneurial, innovaon, and New York State economic development community.', text='Thank you for  subming a grant applicaon for the Jeff Lawrence Innovaon Fund. For Round 2 of the 2024 Manufacturing  Grants,  we  received  58  eligible  applicaons  that  were  carefully  reviewed  by  our  panel  of individuals with experse within the manufacturing, entrepreneurial, innovaon, and New York State economic development community.'), TextItem(self_ref='#/texts/9', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=436.6969909667969, r=563.2479858398438, b=377.7090148925781, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 450))], orig=\"We regret to inform you that the applicaon submied for the Research Foundaon of the City University of New York on behalf of Advanced Science Research Center/ Kepco, Inc. project was not selected as one of the grantees. As in past years, many great applicaons were received resulng in a very compeve round. Upon request, a member  of  FuzeHub's  Jeff  Lawrence  Innovaon  Fund  team  can  provide  a  digital  debrief  of  your  applicaon submission.\", text=\"We regret to inform you that the applicaon submied for the Research Foundaon of the City University of New York on behalf of Advanced Science Research Center/ Kepco, Inc. project was not selected as one of the grantees. As in past years, many great applicaons were received resulng in a very compeve round. Upon request, a member  of  FuzeHub's  Jeff  Lawrence  Innovaon  Fund  team  can  provide  a  digital  debrief  of  your  applicaon submission.\"), TextItem(self_ref='#/texts/10', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=355.6969909667969, r=529.2230224609375, b=337.2090148925781, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 109))], orig='To see who got awarded, you can watch the video announcement here: hps://www.youtube.com/watch? v=NzfYZeW-zyQ', text='To see who got awarded, you can watch the video announcement here: hps://www.youtube.com/watch? v=NzfYZeW-zyQ'), TextItem(self_ref='#/texts/11', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=315.1969909667969, r=563.25, b=256.2090148925781, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 527))], orig=\"If  you  are  not  already  on  our  email  list,  we  encourage  you  and  your  industry  partner  to  sign  up  for  FuzeHub's newsleer (by clicking 'Subscribe' at the top of our homepage hps://fuzehub.com/) to stay updated on FuzeHub acvies and events around the state. As a statewide resource to manufacturers, we have several programs and iniaves that work to accelerate the growth of small-to-medium manufacturing and technology companies by connecng them to reliable, targeted soluons and experse within New York State.\", text=\"If  you  are  not  already  on  our  email  list,  we  encourage  you  and  your  industry  partner  to  sign  up  for  FuzeHub's newsleer (by clicking 'Subscribe' at the top of our homepage hps://fuzehub.com/) to stay updated on FuzeHub acvies and events around the state. As a statewide resource to manufacturers, we have several programs and iniaves that work to accelerate the growth of small-to-medium manufacturing and technology companies by connecng them to reliable, targeted soluons and experse within New York State.\"), TextItem(self_ref='#/texts/12', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=234.19700622558594, r=563.2429809570312, b=215.70899963378906, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 198))], orig='Thank  you  for  your  efforts  on  behalf  of  the  small  businesses  you  work  with.  Please  connue  to  visit www.fuzehub.com/innovaon-fund for updated informaon on all Innovaon Fund programs.', text='Thank  you  for  your  efforts  on  behalf  of  the  small  businesses  you  work  with.  Please  connue  to  visit www.fuzehub.com/innovaon-fund for updated informaon on all Innovaon Fund programs.'), TextItem(self_ref='#/texts/13', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=180.19700622558594, r=96.08999633789062, b=175.20899963378906, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 10))], orig='Sincerely,', text='Sincerely,'), TextItem(self_ref='#/texts/14', parent=RefItem(cref='#/body'), children=[], content_layer=<ContentLayer.BODY: 'body'>, label=<DocItemLabel.TEXT: 'text'>, prov=[ProvenanceItem(page_no=1, bbox=BoundingBox(l=54.0, t=166.69700622558594, r=194.2830047607422, b=161.70899963378906, coord_origin=<CoordOrigin.BOTTOMLEFT: 'BOTTOMLEFT'>), charspan=(0, 26))], orig='FuzeHub Innovaon Fund Team', text='FuzeHub Innovaon Fund Team')]\n",
      "- version: 1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27266/2765983848.py:5: DeprecationWarning: deprecated\n",
      "  value = getattr(document, attr)\n"
     ]
    }
   ],
   "source": [
    "print(\"Document attributes (data):\")\n",
    "for attr in dir(document):\n",
    "    if not attr.startswith('_'):  # Skip private attributes\n",
    "        try:\n",
    "            value = getattr(document, attr)\n",
    "            if not callable(value):  # Only non-callable (attributes)\n",
    "                print(f\"- {attr}: {value}\")\n",
    "        except Exception as e:\n",
    "            print(f\"- {attr}: Error accessing ({str(e)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document methods (functions):\n",
      "- add_code()\n",
      "- add_group()\n",
      "- add_heading()\n",
      "- add_list_item()\n",
      "- add_page()\n",
      "- add_picture()\n",
      "- add_table()\n",
      "- add_text()\n",
      "- add_title()\n",
      "- check_version_is_compatible()\n",
      "- construct()\n",
      "- copy()\n",
      "- dict()\n",
      "- export_to_dict()\n",
      "- export_to_document_tokens()\n",
      "- export_to_element_tree()\n",
      "- export_to_html()\n",
      "- export_to_markdown()\n",
      "- export_to_text()\n",
      "- from_orm()\n",
      "- iterate_items()\n",
      "- json()\n",
      "- load_from_json()\n",
      "- model_construct()\n",
      "- model_copy()\n",
      "- model_dump()\n",
      "- model_dump_json()\n",
      "- model_json_schema()\n",
      "- model_parametrized_name()\n",
      "- model_post_init()\n",
      "- model_rebuild()\n",
      "- model_validate()\n",
      "- model_validate_json()\n",
      "- model_validate_strings()\n",
      "- num_pages()\n",
      "- parse_file()\n",
      "- parse_obj()\n",
      "- parse_raw()\n",
      "- print_element_tree()\n",
      "- save_as_document_tokens()\n",
      "- save_as_html()\n",
      "- save_as_json()\n",
      "- save_as_markdown()\n",
      "- save_as_yaml()\n",
      "- schema()\n",
      "- schema_json()\n",
      "- transform_to_content_layer()\n",
      "- update_forward_refs()\n",
      "- validate()\n",
      "- validate_document()\n",
      "- validate_tree()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27266/2206493520.py:5: DeprecationWarning: deprecated\n",
      "  value = getattr(document, attr)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDocument methods (functions):\")\n",
    "for attr in dir(document):\n",
    "    if not attr.startswith('_'):  # Skip private attributes\n",
    "        try:\n",
    "            value = getattr(document, attr)\n",
    "            if callable(value):  # Only callable (methods)\n",
    "                print(f\"- {attr}()\")\n",
    "        except Exception as e:\n",
    "            print(f\"- {attr}: Error accessing ({str(e)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Text Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEXT ELEMENTS STRUCTURE ===\n",
      "\n",
      "Text Element #1:\n",
      "Type: SectionHeaderItem\n",
      "Text (61 chars, 13 tokens): FuzeHub Manufacturing Grant 2024 Round 2 Application Decision\n",
      "Label: section_header\n",
      "Heading Level: 1\n",
      "Page Numbers: [1]\n",
      "Bounding Box: left=54.0, top=743.927001953125, right=436.2510070800781, bottom=737.0759887695312\n",
      "\n",
      "Text Element #2:\n",
      "Type: SectionHeaderItem\n",
      "Text (31 chars, 13 tokens): FuzeHub Fund <fund@fuzehub.com>\n",
      "Label: section_header\n",
      "Heading Level: 1\n",
      "Page Numbers: [1]\n",
      "Bounding Box: left=54.0, top=718.6519775390625, right=254.47900390625, bottom=712.2039794921875\n",
      "\n",
      "Text Element #3:\n",
      "Type: TextItem\n",
      "Text (22 chars, 13 tokens): Wed 2024-07-24 9:26 AM\n",
      "Label: text\n",
      "Page Numbers: [1]\n",
      "Bounding Box: left=54.0, top=701.552001953125, right=155.86099243164062, bottom=696.7160034179688\n",
      "\n",
      "Text Element #4:\n",
      "Type: TextItem\n",
      "Text (44 chars, 17 tokens): To:  Samantha Roberts <sroberts@gc.cuny.edu>\n",
      "Label: text\n",
      "Page Numbers: [1]\n",
      "Bounding Box: left=54.0, top=685.802, right=242.641, bottom=680.966\n",
      "\n",
      "Text Element #5:\n",
      "Type: TextItem\n",
      "Text (81 chars, 36 tokens): Cc:  Yuki Chen <xchen4@gc.cuny.edu>;  markk@kepcopower.com <markk@kepcopower.com>\n",
      "Label: text\n",
      "Page Numbers: [1]\n",
      "Bounding Box: left=54.0, top=673.802, right=424.985, bottom=668.966\n",
      "\n",
      "Text Element #6:\n",
      "Type: TextItem\n",
      "Text (128 chars, 27 tokens): * This email originates from a sender outside of CUNY. Verify the sender before replying or clicking...\n",
      "Label: text\n",
      "Page Numbers: [1]\n",
      "Bounding Box: left=92.37899780273438, top=628.2769775390625, right=524.8590087890625, bottom=612.593994140625\n",
      "\n",
      "Text Element #7:\n",
      "Type: TextItem\n",
      "Text (13 chars, 7 tokens): July 24, 2024\n",
      "Label: text\n",
      "Page Numbers: [1]\n",
      "Bounding Box: left=54.0, top=571.697021484375, right=111.93299865722656, bottom=566.708984375\n",
      "\n",
      "Text Element #8:\n",
      "Type: TextItem\n",
      "Text (26 chars, 6 tokens): Dear Dr. Samantha Roberts,\n",
      "Label: text\n",
      "Page Numbers: [1]\n",
      "Bounding Box: left=54.0, top=531.197021484375, right=177.17799377441406, bottom=526.208984375\n",
      "\n",
      "Text Element #9:\n",
      "Type: TextItem\n",
      "Text (346 chars, 84 tokens): Thank you for  subming a grant applicaon for the Jeff Lawrence Innovaon Fund. For Round 2 of the 202...\n",
      "Label: text\n",
      "Page Numbers: [1]\n",
      "Bounding Box: left=54.0, top=504.1969909667969, right=563.2479858398438, bottom=458.7090148925781\n",
      "\n",
      "Text Element #10:\n",
      "Type: TextItem\n",
      "Text (450 chars, 120 tokens): We regret to inform you that the applicaon submied for the Research Foundaon of the City University ...\n",
      "Label: text\n",
      "Page Numbers: [1]\n",
      "Bounding Box: left=54.0, top=436.6969909667969, right=563.2479858398438, bottom=377.7090148925781\n",
      "\n",
      "Text Element #11:\n",
      "Type: TextItem\n",
      "Text (109 chars, 31 tokens): To see who got awarded, you can watch the video announcement here: hps://www.youtube.com/watch? v=Nz...\n",
      "Label: text\n",
      "Page Numbers: [1]\n",
      "Bounding Box: left=54.0, top=355.6969909667969, right=529.2230224609375, bottom=337.2090148925781\n",
      "\n",
      "Text Element #12:\n",
      "Type: TextItem\n",
      "Text (527 chars, 133 tokens): If  you  are  not  already  on  our  email  list,  we  encourage  you  and  your  industry  partner ...\n",
      "Label: text\n",
      "Page Numbers: [1]\n",
      "Bounding Box: left=54.0, top=315.1969909667969, right=563.25, bottom=256.2090148925781\n",
      "\n",
      "Text Element #13:\n",
      "Type: TextItem\n",
      "Text (198 chars, 62 tokens): Thank  you  for  your  efforts  on  behalf  of  the  small  businesses  you  work  with.  Please  co...\n",
      "Label: text\n",
      "Page Numbers: [1]\n",
      "Bounding Box: left=54.0, top=234.19700622558594, right=563.2429809570312, bottom=215.70899963378906\n",
      "\n",
      "Text Element #14:\n",
      "Type: TextItem\n",
      "Text (10 chars, 3 tokens): Sincerely,\n",
      "Label: text\n",
      "Page Numbers: [1]\n",
      "Bounding Box: left=54.0, top=180.19700622558594, right=96.08999633789062, bottom=175.20899963378906\n",
      "\n",
      "Text Element #15:\n",
      "Type: TextItem\n",
      "Text (26 chars, 8 tokens): FuzeHub Innovaon Fund Team\n",
      "Label: text\n",
      "Page Numbers: [1]\n",
      "Bounding Box: left=54.0, top=166.69700622558594, right=194.2830047607422, bottom=161.70899963378906\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== TEXT ELEMENTS STRUCTURE ===\")\n",
    "for i, text_item in enumerate(document.texts):\n",
    "    print(f\"\\nText Element #{i+1}:\")\n",
    "    \n",
    "    # Get the type of the text element\n",
    "    element_type = type(text_item).__name__\n",
    "    print(f\"Type: {element_type}\")\n",
    "    \n",
    "    # Print text content with length information\n",
    "    text_length = len(text_item.text)\n",
    "    token_count = tokenizer.count_tokens(text_item.text)\n",
    "    print(f\"Text ({text_length} chars, {token_count} tokens): {text_item.text[:100]}...\" if text_length > 100 \n",
    "          else f\"Text ({text_length} chars, {token_count} tokens): {text_item.text}\")\n",
    "    \n",
    "    # Print other attributes based on the element type\n",
    "    if hasattr(text_item, 'label'):\n",
    "        print(f\"Label: {text_item.label}\")\n",
    "    \n",
    "    if hasattr(text_item, 'level') and element_type == 'SectionHeaderItem':\n",
    "        print(f\"Heading Level: {text_item.level}\")\n",
    "    \n",
    "    if hasattr(text_item, 'prov') and text_item.prov:\n",
    "        page_numbers = [prov.page_no for prov in text_item.prov]\n",
    "        print(f\"Page Numbers: {page_numbers}\")\n",
    "        \n",
    "        # Get bounding box information if available\n",
    "        if hasattr(text_item.prov[0], 'bbox'):\n",
    "            bbox = text_item.prov[0].bbox\n",
    "            print(f\"Bounding Box: left={bbox.l}, top={bbox.t}, right={bbox.r}, bottom={bbox.b}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ELEMENT TYPE COUNTS ===\n",
      "SectionHeaderItem: 2\n",
      "TextItem: 13\n"
     ]
    }
   ],
   "source": [
    "# Count the different types of elements\n",
    "element_types = {}\n",
    "for text_item in document.texts:\n",
    "    element_type = type(text_item).__name__\n",
    "    element_types[element_type] = element_types.get(element_type, 0) + 1\n",
    "\n",
    "print(\"\\n=== ELEMENT TYPE COUNTS ===\")\n",
    "for element_type, count in element_types.items():\n",
    "    print(f\"{element_type}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of list items found: 0\n"
     ]
    }
   ],
   "source": [
    "list_items = [item for item in document.texts if type(item).__name__ == 'ListItem']\n",
    "print(f\"\\nNumber of list items found: {len(list_items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total text length: 2087 characters\n",
      "\n",
      "First 200 chars of text: FuzeHub Manufacturing Grant 2024 Round 2 Application Decision FuzeHub Fund <fund@fuzehub.com> Wed 2024-07-24 9:26 AM To:  Samantha Roberts <sroberts@gc.cuny.edu> Cc:  Yuki Chen <xchen4@gc.cuny.edu>;  ...\n"
     ]
    }
   ],
   "source": [
    "full_text = \"\"\n",
    "for text_item in document.texts:\n",
    "    full_text += text_item.text + \" \"\n",
    "print(f\"Total text length: {len(full_text)} characters\")\n",
    "print(f\"\\nFirst 200 chars of text: {full_text[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type hint for texts: typing.List[typing.Union[docling_core.types.doc.document.SectionHeaderItem, docling_core.types.doc.document.ListItem, docling_core.types.doc.document.TextItem, docling_core.types.doc.document.CodeItem]]\n"
     ]
    }
   ],
   "source": [
    "# Check the type annotation for document.texts\n",
    "import inspect\n",
    "from typing import get_type_hints\n",
    "\n",
    "# This might work depending on how Docling is implemented\n",
    "type_hints = get_type_hints(type(document))\n",
    "if 'texts' in type_hints:\n",
    "    print(f\"Type hint for texts: {type_hints['texts']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full type hint: typing.List[typing.Union[docling_core.types.doc.document.SectionHeaderItem, docling_core.types.doc.document.ListItem, docling_core.types.doc.document.TextItem, docling_core.types.doc.document.CodeItem]]\n",
      "\n",
      "Text element types:\n",
      "- SectionHeaderItem\n",
      "- ListItem\n",
      "- TextItem\n",
      "- CodeItem\n"
     ]
    }
   ],
   "source": [
    "type_hints = get_type_hints(type(document))\n",
    "if 'texts' in type_hints:\n",
    "    type_hint_str = str(type_hints['texts'])\n",
    "    print(f\"Full type hint: {type_hint_str}\")\n",
    "    \n",
    "    # Extract just the class names\n",
    "    if 'Union[' in type_hint_str:\n",
    "        # Extract the part between Union[ and ]\n",
    "        union_content = type_hint_str.split('Union[')[1].split(']')[0]\n",
    "        \n",
    "        # Split by comma and extract class names\n",
    "        class_paths = [path.strip() for path in union_content.split(',')]\n",
    "        class_names = [path.split('.')[-1] for path in class_paths]\n",
    "        \n",
    "        print(\"\\nText element types:\")\n",
    "        for class_name in class_names:\n",
    "            print(f\"- {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEXT ELEMENT ATTRIBUTES ===\n",
      "\n",
      "Text Element #1:\n",
      "Type: SectionHeaderItem\n",
      "Text: FuzeHub Manufacturing Grant 2024 Round 2 Applicati...\n",
      "Other attributes:\n",
      "  - content_layer: ContentLayer.BODY\n",
      "  - model_extra: None\n",
      "  - model_fields_set: {'level', 'orig', 'self_ref', 'parent', 'text'}\n",
      "  - orig: FuzeHub Manufacturing Grant 2024 Round 2 Application Decision\n",
      "  - parent: cref='#/body'\n",
      "  - self_ref: #/texts/0\n",
      "\n",
      "Text Element #2:\n",
      "Type: SectionHeaderItem\n",
      "Text: FuzeHub Fund <fund@fuzehub.com>\n",
      "Other attributes:\n",
      "  - content_layer: ContentLayer.BODY\n",
      "  - model_extra: None\n",
      "  - model_fields_set: {'level', 'orig', 'self_ref', 'parent', 'text'}\n",
      "  - orig: FuzeHub Fund <fund@fuzehub.com>\n",
      "  - parent: cref='#/body'\n",
      "  - self_ref: #/texts/1\n",
      "\n",
      "Text Element #3:\n",
      "Type: TextItem\n",
      "Text: Wed 2024-07-24 9:26 AM\n",
      "Other attributes:\n",
      "  - content_layer: ContentLayer.BODY\n",
      "  - model_extra: None\n",
      "  - model_fields_set: {'orig', 'label', 'self_ref', 'parent', 'text'}\n",
      "  - orig: Wed 2024-07-24 9:26 AM\n",
      "  - parent: cref='#/body'\n",
      "  - self_ref: #/texts/2\n",
      "\n",
      "Text Element #4:\n",
      "Type: TextItem\n",
      "Text: To:  Samantha Roberts <sroberts@gc.cuny.edu>\n",
      "Other attributes:\n",
      "  - content_layer: ContentLayer.BODY\n",
      "  - model_extra: None\n",
      "  - model_fields_set: {'orig', 'label', 'self_ref', 'parent', 'text'}\n",
      "  - orig: To:  Samantha Roberts <sroberts@gc.cuny.edu>\n",
      "  - parent: cref='#/groups/0'\n",
      "  - self_ref: #/texts/3\n",
      "\n",
      "Text Element #5:\n",
      "Type: TextItem\n",
      "Text: Cc:  Yuki Chen <xchen4@gc.cuny.edu>;  markk@kepcop...\n",
      "Other attributes:\n",
      "  - content_layer: ContentLayer.BODY\n",
      "  - model_extra: None\n",
      "  - model_fields_set: {'orig', 'label', 'self_ref', 'parent', 'text'}\n",
      "  - orig: Cc:  Yuki Chen <xchen4@gc.cuny.edu>;  markk@kepcopower.com <markk@kepcopower.com>\n",
      "  - parent: cref='#/groups/0'\n",
      "  - self_ref: #/texts/4\n",
      "\n",
      "Text Element #6:\n",
      "Type: TextItem\n",
      "Text: * This email originates from a sender outside of C...\n",
      "Other attributes:\n",
      "  - content_layer: ContentLayer.BODY\n",
      "  - model_extra: None\n",
      "  - model_fields_set: {'orig', 'label', 'self_ref', 'parent', 'text'}\n",
      "  - orig: * This email originates from a sender outside of CUNY. Verify the sender before replying or clicking on links and attachments. *\n",
      "  - parent: cref='#/body'\n",
      "  - self_ref: #/texts/5\n",
      "\n",
      "Text Element #7:\n",
      "Type: TextItem\n",
      "Text: July 24, 2024\n",
      "Other attributes:\n",
      "  - content_layer: ContentLayer.BODY\n",
      "  - model_extra: None\n",
      "  - model_fields_set: {'orig', 'label', 'self_ref', 'parent', 'text'}\n",
      "  - orig: July 24, 2024\n",
      "  - parent: cref='#/body'\n",
      "  - self_ref: #/texts/6\n",
      "\n",
      "Text Element #8:\n",
      "Type: TextItem\n",
      "Text: Dear Dr. Samantha Roberts,\n",
      "Other attributes:\n",
      "  - content_layer: ContentLayer.BODY\n",
      "  - model_extra: None\n",
      "  - model_fields_set: {'orig', 'label', 'self_ref', 'parent', 'text'}\n",
      "  - orig: Dear Dr. Samantha Roberts,\n",
      "  - parent: cref='#/body'\n",
      "  - self_ref: #/texts/7\n",
      "\n",
      "Text Element #9:\n",
      "Type: TextItem\n",
      "Text: Thank you for  subming a grant applicaon for the J...\n",
      "Other attributes:\n",
      "  - content_layer: ContentLayer.BODY\n",
      "  - model_extra: None\n",
      "  - model_fields_set: {'orig', 'label', 'self_ref', 'parent', 'text'}\n",
      "  - orig: Thank you for  subming a grant applicaon for the Jeff Lawrence Innovaon Fund. For Round 2 of the 2024 Manufacturing  Grants,  we  received  58  eligible  applicaons  that  were  carefully  reviewed  by  our  panel  of individuals with experse within the manufacturing, entrepreneurial, innovaon, and New York State economic development community.\n",
      "  - parent: cref='#/body'\n",
      "  - self_ref: #/texts/8\n",
      "\n",
      "Text Element #10:\n",
      "Type: TextItem\n",
      "Text: We regret to inform you that the applicaon submied...\n",
      "Other attributes:\n",
      "  - content_layer: ContentLayer.BODY\n",
      "  - model_extra: None\n",
      "  - model_fields_set: {'orig', 'label', 'self_ref', 'parent', 'text'}\n",
      "  - orig: We regret to inform you that the applicaon submied for the Research Foundaon of the City University of New York on behalf of Advanced Science Research Center/ Kepco, Inc. project was not selected as one of the grantees. As in past years, many great applicaons were received resulng in a very compeve round. Upon request, a member  of  FuzeHub's  Jeff  Lawrence  Innovaon  Fund  team  can  provide  a  digital  debrief  of  your  applicaon submission.\n",
      "  - parent: cref='#/body'\n",
      "  - self_ref: #/texts/9\n",
      "\n",
      "Text Element #11:\n",
      "Type: TextItem\n",
      "Text: To see who got awarded, you can watch the video an...\n",
      "Other attributes:\n",
      "  - content_layer: ContentLayer.BODY\n",
      "  - model_extra: None\n",
      "  - model_fields_set: {'orig', 'label', 'self_ref', 'parent', 'text'}\n",
      "  - orig: To see who got awarded, you can watch the video announcement here: hps://www.youtube.com/watch? v=NzfYZeW-zyQ\n",
      "  - parent: cref='#/body'\n",
      "  - self_ref: #/texts/10\n",
      "\n",
      "Text Element #12:\n",
      "Type: TextItem\n",
      "Text: If  you  are  not  already  on  our  email  list, ...\n",
      "Other attributes:\n",
      "  - content_layer: ContentLayer.BODY\n",
      "  - model_extra: None\n",
      "  - model_fields_set: {'orig', 'label', 'self_ref', 'parent', 'text'}\n",
      "  - orig: If  you  are  not  already  on  our  email  list,  we  encourage  you  and  your  industry  partner  to  sign  up  for  FuzeHub's newsleer (by clicking 'Subscribe' at the top of our homepage hps://fuzehub.com/) to stay updated on FuzeHub acvies and events around the state. As a statewide resource to manufacturers, we have several programs and iniaves that work to accelerate the growth of small-to-medium manufacturing and technology companies by connecng them to reliable, targeted soluons and experse within New York State.\n",
      "  - parent: cref='#/body'\n",
      "  - self_ref: #/texts/11\n",
      "\n",
      "Text Element #13:\n",
      "Type: TextItem\n",
      "Text: Thank  you  for  your  efforts  on  behalf  of  th...\n",
      "Other attributes:\n",
      "  - content_layer: ContentLayer.BODY\n",
      "  - model_extra: None\n",
      "  - model_fields_set: {'orig', 'label', 'self_ref', 'parent', 'text'}\n",
      "  - orig: Thank  you  for  your  efforts  on  behalf  of  the  small  businesses  you  work  with.  Please  connue  to  visit www.fuzehub.com/innovaon-fund for updated informaon on all Innovaon Fund programs.\n",
      "  - parent: cref='#/body'\n",
      "  - self_ref: #/texts/12\n",
      "\n",
      "Text Element #14:\n",
      "Type: TextItem\n",
      "Text: Sincerely,\n",
      "Other attributes:\n",
      "  - content_layer: ContentLayer.BODY\n",
      "  - model_extra: None\n",
      "  - model_fields_set: {'orig', 'label', 'self_ref', 'parent', 'text'}\n",
      "  - orig: Sincerely,\n",
      "  - parent: cref='#/body'\n",
      "  - self_ref: #/texts/13\n",
      "\n",
      "Text Element #15:\n",
      "Type: TextItem\n",
      "Text: FuzeHub Innovaon Fund Team\n",
      "Other attributes:\n",
      "  - content_layer: ContentLayer.BODY\n",
      "  - model_extra: None\n",
      "  - model_fields_set: {'orig', 'label', 'self_ref', 'parent', 'text'}\n",
      "  - orig: FuzeHub Innovaon Fund Team\n",
      "  - parent: cref='#/body'\n",
      "  - self_ref: #/texts/14\n"
     ]
    }
   ],
   "source": [
    "# Cell for examining text element attributes\n",
    "print(\"\\n=== TEXT ELEMENT ATTRIBUTES ===\")\n",
    "for i, text_item in enumerate(document.texts):\n",
    "    print(f\"\\nText Element #{i+1}:\")\n",
    "    element_type = type(text_item).__name__\n",
    "    print(f\"Type: {element_type}\")\n",
    "    \n",
    "    # Show text preview\n",
    "    text_preview = text_item.text[:50] + \"...\" if len(text_item.text) > 50 else text_item.text\n",
    "    print(f\"Text: {text_preview}\")\n",
    "    \n",
    "    # Show list-specific attributes\n",
    "    if element_type == 'ListItem':\n",
    "        if hasattr(text_item, 'list_type'):\n",
    "            print(f\"List Type: {text_item.list_type}\")\n",
    "        if hasattr(text_item, 'list_index'):\n",
    "            print(f\"List Index: {text_item.list_index}\")\n",
    "    \n",
    "    # Show all other non-private attributes\n",
    "    print(\"Other attributes:\")\n",
    "    for attr in dir(text_item):\n",
    "        if not attr.startswith('_') and attr not in ['text', 'label', 'level', 'prov', 'list_type', 'list_index']:\n",
    "            try:\n",
    "                value = getattr(text_item, attr)\n",
    "                if not callable(value) and not isinstance(value, (list, dict)) and str(value) != '':\n",
    "                    print(f\"  - {attr}: {value}\")\n",
    "            except Exception:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Furniture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DOCUMENT FURNITURE ===\n",
      "Furniture object type: GroupItem\n",
      "Furniture has no children.\n",
      "\n",
      "Furniture attributes:\n",
      "- content_layer: ContentLayer.FURNITURE\n",
      "- label: unspecified\n",
      "- model_extra: None\n",
      "- model_fields_set: {'content_layer', 'self_ref', 'name'}\n",
      "- name: _root_\n",
      "- parent: None\n",
      "- self_ref: #/furniture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27266/3969607984.py:5: DeprecationWarning: deprecated\n",
      "  if hasattr(document, 'furniture'):\n",
      "/tmp/ipykernel_27266/3969607984.py:6: DeprecationWarning: deprecated\n",
      "  furniture = document.furniture\n"
     ]
    }
   ],
   "source": [
    "# Inspect document furniture\n",
    "print(\"\\n=== DOCUMENT FURNITURE ===\")\n",
    "\n",
    "# Check if furniture exists\n",
    "if hasattr(document, 'furniture'):\n",
    "    furniture = document.furniture\n",
    "    \n",
    "    # Print basic furniture information\n",
    "    print(f\"Furniture object type: {type(furniture).__name__}\")\n",
    "    \n",
    "    # Check if furniture has any children\n",
    "    if hasattr(furniture, 'children') and furniture.children:\n",
    "        print(f\"Number of furniture children: {len(furniture.children)}\")\n",
    "        \n",
    "        # Inspect each furniture child\n",
    "        for i, child in enumerate(furniture.children):\n",
    "            print(f\"\\nFurniture Child #{i+1}:\")\n",
    "            child_type = type(child).__name__\n",
    "            print(f\"Type: {child_type}\")\n",
    "            \n",
    "            # Try to access common attributes\n",
    "            for attr in ['text', 'label', 'name', 'content_layer']:\n",
    "                if hasattr(child, attr):\n",
    "                    value = getattr(child, attr)\n",
    "                    print(f\"{attr}: {value}\")\n",
    "            \n",
    "            # Check for position information\n",
    "            if hasattr(child, 'prov') and child.prov:\n",
    "                page_numbers = [prov.page_no for prov in child.prov]\n",
    "                print(f\"Page Numbers: {page_numbers}\")\n",
    "                \n",
    "                # Get bounding box information if available\n",
    "                if hasattr(child.prov[0], 'bbox'):\n",
    "                    bbox = child.prov[0].bbox\n",
    "                    print(f\"Bounding Box: left={bbox.l}, top={bbox.t}, right={bbox.r}, bottom={bbox.b}\")\n",
    "            \n",
    "            # Show all other attributes\n",
    "            print(\"Other attributes:\")\n",
    "            for attr in dir(child):\n",
    "                if not attr.startswith('_') and attr not in ['text', 'label', 'name', 'content_layer', 'prov', 'children']:\n",
    "                    try:\n",
    "                        value = getattr(child, attr)\n",
    "                        if not callable(value) and not isinstance(value, (list, dict)) and str(value) != '':\n",
    "                            print(f\"  - {attr}: {value}\")\n",
    "                    except Exception:\n",
    "                        pass\n",
    "    else:\n",
    "        print(\"Furniture has no children.\")\n",
    "    \n",
    "    # Show all furniture attributes\n",
    "    print(\"\\nFurniture attributes:\")\n",
    "    for attr in dir(furniture):\n",
    "        if not attr.startswith('_') and attr not in ['children']:\n",
    "            try:\n",
    "                value = getattr(furniture, attr)\n",
    "                if not callable(value) and not isinstance(value, (list, dict)) and str(value) != '':\n",
    "                    print(f\"- {attr}: {value}\")\n",
    "            except Exception as e:\n",
    "                print(f\"- {attr}: Error accessing ({str(e)})\")\n",
    "else:\n",
    "    print(\"Document does not have a furniture attribute.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== UNDERSTANDING DOCLING CHUNKING ===\n",
      "Chunkers in Docling return DocChunk objects that contain:\n",
      "- text: The actual text content of the chunk\n",
      "- meta: Metadata about the chunk (headings, page numbers, etc.)\n",
      "- Chunks are returned as iterators, so we typically convert to list\n",
      "\n",
      "Example chunk structure:\n",
      "- Type: DocChunk\n",
      "- Text length: 22 characters\n",
      "- Text preview: Wed 2024-07-24 9:26 AM...\n",
      "\n",
      "Chunk metadata contains:\n",
      "- captions: None\n",
      "- doc_items: list with 1 items\n",
      "- excluded_embed: list with 4 items\n",
      "- excluded_llm: list with 4 items\n",
      "- headings: list with 1 items\n",
      "- model_computed_fields: dict with 0 items\n",
      "- model_config: dict with 0 items\n",
      "- model_extra: None\n",
      "- model_fields: dict with 6 items\n",
      "- model_fields_set: {'captions', 'headings', 'doc_items', 'origin'}\n",
      "- origin: mimetype='application/pdf' binary_hash=1563881226811200184 filename='grant_decision_email_single_page.pdf' uri=None\n",
      "- schema_name: docling_core.transforms.chunker.DocMeta\n",
      "- version: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== UNDERSTANDING DOCLING CHUNKING ===\")\n",
    "\n",
    "# 1. Import the basic chunkers\n",
    "from docling.chunking import BaseChunker, HierarchicalChunker, HybridChunker\n",
    "\n",
    "# 2. Check what a chunker returns\n",
    "print(\"Chunkers in Docling return DocChunk objects that contain:\")\n",
    "print(\"- text: The actual text content of the chunk\")\n",
    "print(\"- meta: Metadata about the chunk (headings, page numbers, etc.)\")\n",
    "print(\"- Chunks are returned as iterators, so we typically convert to list\")\n",
    "\n",
    "# 3. Let's examine a single chunk to understand its structure\n",
    "chunker = HierarchicalChunker()  # Start with the hierarchical chunker\n",
    "chunks = list(chunker.chunk(document))\n",
    "\n",
    "if chunks:\n",
    "    # Examine the first chunk in detail\n",
    "    first_chunk = chunks[0]\n",
    "    print(\"\\nExample chunk structure:\")\n",
    "    print(f\"- Type: {type(first_chunk).__name__}\")\n",
    "    print(f\"- Text length: {len(first_chunk.text)} characters\")\n",
    "    print(f\"- Text preview: {first_chunk.text[:100]}...\")\n",
    "    \n",
    "    # Examine the metadata\n",
    "    print(\"\\nChunk metadata contains:\")\n",
    "    for attr in dir(first_chunk.meta):\n",
    "        if not attr.startswith('_') and not callable(getattr(first_chunk.meta, attr)):\n",
    "            value = getattr(first_chunk.meta, attr)\n",
    "            if isinstance(value, (list, dict)):\n",
    "                print(f\"- {attr}: {type(value).__name__} with {len(value)} items\")\n",
    "            else:\n",
    "                print(f\"- {attr}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPARING DIFFERENT CHUNKERS ===\n",
      "HierarchicalChunker produced 13 chunks\n",
      "HybridChunker (default) produced 1 chunks\n",
      "HybridChunker (max_tokens=1000) produced 1 chunks\n",
      "\n",
      "Chunker comparison summary:\n",
      "1. HierarchicalChunker: 13 chunks\n",
      "   - First chunk length: 22 chars\n",
      "   - First chunk headings: ['FuzeHub Fund <fund@fuzehub.com>']\n",
      "\n",
      "2. HybridChunker (default): 1 chunks\n",
      "   - First chunk length: 1992 chars\n",
      "   - First chunk headings: ['FuzeHub Fund <fund@fuzehub.com>']\n",
      "\n",
      "3. HybridChunker (max_tokens=100): 1 chunks\n",
      "   - First chunk length: 1992 chars\n",
      "   - First chunk headings: ['FuzeHub Fund <fund@fuzehub.com>']\n"
     ]
    }
   ],
   "source": [
    "# Compare different chunkers and their output\n",
    "print(\"\\n=== COMPARING DIFFERENT CHUNKERS ===\")\n",
    "\n",
    "# 1. HierarchicalChunker\n",
    "hierarchical_chunker = HierarchicalChunker()\n",
    "hierarchical_chunks = list(hierarchical_chunker.chunk(document))\n",
    "print(f\"HierarchicalChunker produced {len(hierarchical_chunks)} chunks\")\n",
    "\n",
    "# 2. HybridChunker with default settings\n",
    "hybrid_chunker = HybridChunker(tokenizer=tokenizer)\n",
    "hybrid_chunks = list(hybrid_chunker.chunk(document))\n",
    "print(f\"HybridChunker (default) produced {len(hybrid_chunks)} chunks\")\n",
    "\n",
    "# 3. HybridChunker with custom max_tokens\n",
    "hybrid_chunker_custom = HybridChunker(tokenizer=tokenizer, max_tokens=1000)\n",
    "hybrid_custom_chunks = list(hybrid_chunker_custom.chunk(document))\n",
    "print(f\"HybridChunker (max_tokens=1000) produced {len(hybrid_custom_chunks)} chunks\")\n",
    "\n",
    "# Print a summary of each chunker's output\n",
    "print(\"\\nChunker comparison summary:\")\n",
    "print(f\"1. HierarchicalChunker: {len(hierarchical_chunks)} chunks\")\n",
    "print(f\"   - First chunk length: {len(hierarchical_chunks[0].text)} chars\")\n",
    "print(f\"   - First chunk headings: {hierarchical_chunks[0].meta.headings}\")\n",
    "\n",
    "print(f\"\\n2. HybridChunker (default): {len(hybrid_chunks)} chunks\")\n",
    "print(f\"   - First chunk length: {len(hybrid_chunks[0].text)} chars\")\n",
    "print(f\"   - First chunk headings: {hybrid_chunks[0].meta.headings}\")\n",
    "\n",
    "print(f\"\\n3. HybridChunker (max_tokens=100): {len(hybrid_custom_chunks)} chunks\")\n",
    "print(f\"   - First chunk length: {len(hybrid_custom_chunks[0].text)} chars\")\n",
    "print(f\"   - First chunk headings: {hybrid_custom_chunks[0].meta.headings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INVESTIGATING HYBRIDCHUNKER BEHAVIOR ===\n",
      "Total document text: 2087 characters, 575 tokens\n",
      "Default max_tokens for HybridChunker: 2048\n",
      "Is document smaller than default max_tokens? True\n",
      "\n",
      "=== TRYING HYBRIDCHUNKER WITH EXPLICIT PARAMETERS ===\n",
      "HybridChunker with restrictive parameters produced 16 chunks\n"
     ]
    }
   ],
   "source": [
    "# Investigate why HybridChunker is creating only one chunk\n",
    "print(\"\\n=== INVESTIGATING HYBRIDCHUNKER BEHAVIOR ===\")\n",
    "\n",
    "# 1. Check the total token count of the document\n",
    "full_text = \"\"\n",
    "for text_item in document.texts:\n",
    "    full_text += text_item.text + \" \"\n",
    "total_tokens = tokenizer.count_tokens(full_text)\n",
    "print(f\"Total document text: {len(full_text)} characters, {total_tokens} tokens\")\n",
    "\n",
    "# 2. Check if the document is small enough to fit in one chunk\n",
    "print(f\"Default max_tokens for HybridChunker: 2048\")\n",
    "print(f\"Is document smaller than default max_tokens? {total_tokens < 2048}\")\n",
    "\n",
    "# 3. Try with explicit parameters and debug output\n",
    "print(\"\\n=== TRYING HYBRIDCHUNKER WITH EXPLICIT PARAMETERS ===\")\n",
    "hybrid_chunker_debug = HybridChunker(\n",
    "    tokenizer=tokenizer,\n",
    "    max_tokens=100,  # Very small limit\n",
    "    merge_peers=False,  # Don't merge sections\n",
    "    min_chunk_chars=10,  # Allow very small chunks\n",
    "    min_chunk_size_ratio=0.1  # Allow chunks as small as 10% of max_tokens\n",
    ")\n",
    "\n",
    "# Get chunks and examine them\n",
    "debug_chunks = list(hybrid_chunker_debug.chunk(document))\n",
    "print(f\"HybridChunker with restrictive parameters produced {len(debug_chunks)} chunks\")\n",
    "\n",
    "# Check the token count of the single chunk if there's only one\n",
    "if len(debug_chunks) == 1:\n",
    "    chunk_tokens = tokenizer.count_tokens(debug_chunks[0].text)\n",
    "    print(f\"Single chunk token count: {chunk_tokens}\")\n",
    "    print(f\"Exceeds max_tokens limit of 100? {chunk_tokens > 100}\")\n",
    "    \n",
    "    # Check if the document has a structure that prevents splitting\n",
    "    print(\"\\nDocument structure analysis:\")\n",
    "    print(f\"Number of text elements: {len(document.texts)}\")\n",
    "    print(f\"Number of section headers: {sum(1 for item in document.texts if type(item).__name__ == 'SectionHeaderItem')}\")\n",
    "    \n",
    "    # Try to understand why it's not splitting\n",
    "    print(\"\\nPossible reasons for not splitting:\")\n",
    "    print(\"1. Document might have a structure that HybridChunker considers atomic\")\n",
    "    print(\"2. There might be a minimum chunk size that prevents splitting\")\n",
    "    print(\"3. The chunker might be configured to keep certain elements together\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXAMINING HYBRIDCHUNKER CHUNKS ===\n",
      "Number of chunks: 16\n",
      "\n",
      "Chunk 1:\n",
      "- Length: 22 chars, 13 tokens\n",
      "- Headings: ['FuzeHub Fund <fund@fuzehub.com>']\n",
      "- Preview: Wed 2024-07-24 9:26 AM\n",
      "\n",
      "Chunk 2:\n",
      "- Length: 44 chars, 17 tokens\n",
      "- Headings: ['FuzeHub Fund <fund@fuzehub.com>']\n",
      "- Preview: To:  Samantha Roberts <sroberts@gc.cuny.edu>\n",
      "\n",
      "Chunk 3:\n",
      "- Length: 81 chars, 36 tokens\n",
      "- Headings: ['FuzeHub Fund <fund@fuzehub.com>']\n",
      "- Preview: Cc:  Yuki Chen <xchen4@gc.cuny.edu>;  markk@kepcop...\n",
      "\n",
      "Chunk 4:\n",
      "- Length: 128 chars, 27 tokens\n",
      "- Headings: ['FuzeHub Fund <fund@fuzehub.com>']\n",
      "- Preview: * This email originates from a sender outside of C...\n",
      "\n",
      "Chunk 5:\n",
      "- Length: 13 chars, 7 tokens\n",
      "- Headings: ['FuzeHub Fund <fund@fuzehub.com>']\n",
      "- Preview: July 24, 2024\n",
      "\n",
      "Chunk 6:\n",
      "- Length: 26 chars, 6 tokens\n",
      "- Headings: ['FuzeHub Fund <fund@fuzehub.com>']\n",
      "- Preview: Dear Dr. Samantha Roberts,\n",
      "\n",
      "Chunk 7:\n",
      "- Length: 346 chars, 84 tokens\n",
      "- Headings: ['FuzeHub Fund <fund@fuzehub.com>']\n",
      "- Preview: Thank you for  subming a grant applicaon for the J...\n",
      "\n",
      "Chunk 8:\n",
      "- Length: 344 chars, 87 tokens\n",
      "- Headings: ['FuzeHub Fund <fund@fuzehub.com>']\n",
      "- Preview: We regret to inform you that the applicaon submied...\n",
      "\n",
      "Chunk 9:\n",
      "- Length: 104 chars, 32 tokens\n",
      "- Headings: ['FuzeHub Fund <fund@fuzehub.com>']\n",
      "- Preview: Jeff  Lawrence  Innovaon  Fund  team  can  provide...\n",
      "\n",
      "Chunk 10:\n",
      "- Length: 109 chars, 31 tokens\n",
      "- Headings: ['FuzeHub Fund <fund@fuzehub.com>']\n",
      "- Preview: To see who got awarded, you can watch the video an...\n",
      "\n",
      "Chunk 11:\n",
      "- Length: 118 chars, 40 tokens\n",
      "- Headings: ['FuzeHub Fund <fund@fuzehub.com>']\n",
      "- Preview: If  you  are  not  already  on  our  email  list, ...\n",
      "\n",
      "Chunk 12:\n",
      "- Length: 384 chars, 87 tokens\n",
      "- Headings: ['FuzeHub Fund <fund@fuzehub.com>']\n",
      "- Preview: FuzeHub's newsleer (by clicking 'Subscribe' at the...\n",
      "\n",
      "Chunk 13:\n",
      "- Length: 22 chars, 5 tokens\n",
      "- Headings: ['FuzeHub Fund <fund@fuzehub.com>']\n",
      "- Preview: within New York State.\n",
      "\n",
      "Chunk 14:\n",
      "- Length: 198 chars, 62 tokens\n",
      "- Headings: ['FuzeHub Fund <fund@fuzehub.com>']\n",
      "- Preview: Thank  you  for  your  efforts  on  behalf  of  th...\n",
      "\n",
      "Chunk 15:\n",
      "- Length: 10 chars, 3 tokens\n",
      "- Headings: ['FuzeHub Fund <fund@fuzehub.com>']\n",
      "- Preview: Sincerely,\n",
      "\n",
      "Chunk 16:\n",
      "- Length: 26 chars, 8 tokens\n",
      "- Headings: ['FuzeHub Fund <fund@fuzehub.com>']\n",
      "- Preview: FuzeHub Innovaon Fund Team\n"
     ]
    }
   ],
   "source": [
    "# Examine the chunks produced by the restrictive HybridChunker\n",
    "print(\"\\n=== EXAMINING HYBRIDCHUNKER CHUNKS ===\")\n",
    "\n",
    "hybrid_chunker_detailed = HybridChunker(\n",
    "    tokenizer=tokenizer,\n",
    "    max_tokens=100,  # Small token limit\n",
    "    merge_peers=False,  # Don't merge sections\n",
    "    min_chunk_chars=10,  # Allow small chunks\n",
    "    min_chunk_size_ratio=0.1  # Allow chunks as small as 10% of max_tokens\n",
    ")\n",
    "\n",
    "detailed_chunks = list(hybrid_chunker_detailed.chunk(document))\n",
    "print(f\"Number of chunks: {len(detailed_chunks)}\")\n",
    "\n",
    "# Examine each chunk\n",
    "for i, chunk in enumerate(detailed_chunks):\n",
    "    token_count = tokenizer.count_tokens(chunk.text)\n",
    "    print(f\"\\nChunk {i+1}:\")\n",
    "    print(f\"- Length: {len(chunk.text)} chars, {token_count} tokens\")\n",
    "    print(f\"- Headings: {chunk.meta.headings}\")\n",
    "    \n",
    "    # Get the first few words to understand the content\n",
    "    preview = chunk.text[:50] + \"...\" if len(chunk.text) > 50 else chunk.text\n",
    "    print(f\"- Preview: {preview}\")\n",
    "    \n",
    "    # Check if the chunk respects the token limit\n",
    "    if token_count > 100:\n",
    "        print(\"  WARNING: Chunk exceeds the max_tokens limit of 100\")\n",
    "        \n",
    "        # Try to understand why\n",
    "        doc_items = chunk.meta.doc_items if hasattr(chunk.meta, 'doc_items') else []\n",
    "        item_types = [type(item).__name__ for item in doc_items]\n",
    "        print(f\"  Contains item types: {set(item_types)}\")\n",
    "        \n",
    "        # Check if it's a single large text item that can't be split\n",
    "        if len(doc_items) == 1:\n",
    "            print(f\"  Single item chunk - cannot be split further\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
